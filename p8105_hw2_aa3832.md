Homework 2
================
Alexey Abramov

## Setup

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(chron)
```

# Problem 1

### Mr. Trash Wheel, sports balls data.

#### Read in and clean up the Mr. Trashwheel dataset

``` r
trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
      janitor::clean_names() %>% 
      drop_na(dumpster) %>% 
      mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls))
```

### Trash Wheel, precipitation data.

#### Read in precipitation excel spreadsheet for the 2018 and 2017 data.

``` r
precip_2018 = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2018 Precipitation",
      skip = 1) %>% 
      janitor::clean_names() %>% 
      drop_na(month) %>% 
      mutate(year = 2018) %>% 
      relocate(year)

precip_2017 = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2017 Precipitation",
      skip = 1) %>% 
      janitor::clean_names() %>% 
      drop_na(month) %>% 
      mutate(year = 2017) %>% 
      relocate(year)
```

#### Binding 2017 and 2018 precipitation data.

``` r
  precip_df = bind_rows(precip_2017, precip_2018)
```

Creating a month number to month name tibble:

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )
```

#### Cleaning up 2017 and 2018 Precipitation Data

Including a month name column and relocating columns for improved
visualization.

``` r
precip_df_2 = 
  left_join(precip_df, month_df, by = "month") %>% 
  relocate(year, month_name, month, total)
```

Total precipitation in 2018 calculation

``` r
sum_precip_2018 = select(precip_2018, total) %>% 
  sum()
```

Median number of sports balls in 2017 calculation

``` r
trashwheel_df_2017_sports_balls = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
      janitor::clean_names() %>% 
      drop_na(dumpster) %>% 
      filter(year == "2017") %>% 
      pull(sports_balls) %>% 
      median()
```

### Mr. Trash Wheel Discussion

These data are obtained from the Mr. Trash Wheel dataset which reports
on discarded items collected from the Inner Harbor in Baltimore, MD and
stores it in a dumpster. There are a total of 344 rows in our final
dataset. These data also include precipitation amounts by month.

In this data set, the median number of sports balls collected in 2017 is
8 and the sum precipitation in 2017 was 70.33 inches.

# Problem 2

## NYC Transit dataset

#### Read in dataset, cleaning up column names

``` r
nyc_transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, 
         route1:route11, entrance_type, entry, vending, ada)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

#### Data cleaning, and recoding entry column to logical vector

``` r
nyc_transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) %>% 
   mutate(entry = ifelse(entry == "NO",0,1))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

## Discussion

This dataset contains information regarding the New York City transit
subway system and reports station name and GPS coordinates, routes
served, as well as entrance information highlighting ADA compliance and
vending. The dataset has 1868 rows and 19 columns.

#### Calculating the number of distinct stations

There are 465 stations in the NYC transit system.

``` r
nrow(distinct(nyc_transit_df, line, station_name))
```

    ## [1] 465

#### Calculating the number of ADA compliant stations

``` r
ada_compliant = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) %>% 
   mutate(ada = ifelse(ada == "TRUE",1,0)) %>% 
    filter(ada == "1") %>% 
    distinct(line, station_name)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nrow(ada_compliant)
```

    ## [1] 84

There are 84 ADA compliant stations in the NYC transit system.

#### Calculating the number of stations with entry that do not have vending.

``` r
entry_vending_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>%
     select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) %>% 
        mutate(vending = ifelse(vending == "YES",1,0)) %>% 
        mutate(entry = ifelse(entry == "NO",0,1)) %>% 
          filter(vending == "0") %>% 
          filter(entry == "1") %>% 
            distinct(line, station_name)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nrow(entry_vending_df)
```

    ## [1] 43

There are 43 stations that have entrances but do not have vending. There
are a total of 465 stations, which means 0.0924731 do not have vending.

#### Reformatting to create distinct route name and route number variables.

``` r
route_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>%
     select(line, station_name, route1:route11, entrance_type, entry, 
            vending, ada) %>% 
              mutate_at(vars(route1:route11), as.character) %>% 
                  pivot_longer(route1:route11, 
                  names_to = "route_number", 
                  values_to = "route_name",
                  names_prefix = "route") %>% 
                    drop_na("route_name") %>% 
                      distinct_at(vars(line, station_name, route_name, 
                                       route_number))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

#### Calculating the number of distinct A train stations

``` r
route_A_df = filter(route_df, route_name == "A")
nrow(route_A_df)
```

    ## [1] 60

``` r
ada_compliant_A_df= 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>%
     select(line, station_name, route1:route11, ada) %>% 
              mutate_at(vars(route1:route11), as.character) %>% 
                  pivot_longer(route1:route11, 
                  names_to = "route_number", 
                  values_to = "route_name",
                  names_prefix = "route") %>% 
                    drop_na("route_name") %>% 
                      distinct(station_name, line, ada)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nrow(ada_compliant_A_df)
```

    ## [1] 465

There are 60 distinct A stations in the NYC transit system. Of which,
465 are ADA compliant.

# Problem 3

#### Read in FiveThirtyEight data pols-month

Data cleaning pols\_month dataset

``` r
library(lubridate)
```

    ## 
    ## Attaching package: 'lubridate'

    ## The following objects are masked from 'package:chron':
    ## 
    ##     days, hours, minutes, seconds, years

    ## The following objects are masked from 'package:base':
    ## 
    ##     date, intersect, setdiff, union

``` r
pols_month_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
    janitor::clean_names() %>% 
      mutate(mon = ymd(mon)) %>% 
      mutate_at(vars(mon), funs(year, month, day)) %>% 
      mutate(president = 
               case_when(
                  prez_gop == 1 ~ "gop",
                  prez_dem == 1 ~ "dem")) %>% 
      subset(select = -c(prez_gop, prez_dem, day, mon))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

    ## Warning: `funs()` is deprecated as of dplyr 0.8.0.
    ## Please use a list of either functions or lambdas: 
    ## 
    ##   # Simple named list: 
    ##   list(mean = mean, median = median)
    ## 
    ##   # Auto named with `tibble::lst()`: 
    ##   tibble::lst(mean, median)
    ## 
    ##   # Using lambdas
    ##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
    ## This warning is displayed once every 8 hours.
    ## Call `lifecycle::last_warnings()` to see where this warning was generated.

Reformatting month number with the month name.

``` r
pols_month_df = 
  left_join(pols_month_df, month_df, by = "month")  %>%        
  relocate(year, month_name, president)
```

Data cleaning snp dataset

``` r
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
    janitor::clean_names() %>% 
    separate(date, into = c("month", "day", "year"), sep="/") %>%  
      mutate_at(vars(month), as.numeric)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Binding to reformat month number to month name in snp dataset

``` r
left_join(snp_df, month_df, by = "month") %>% 
  relocate(year, month_name)
```

    ## # A tibble: 787 x 5
    ##    year  month_name month day   close
    ##    <chr> <chr>      <dbl> <chr> <dbl>
    ##  1 2015  July           7 1     2080.
    ##  2 2015  June           6 1     2063.
    ##  3 2015  May            5 1     2107.
    ##  4 2015  April          4 1     2086.
    ##  5 2015  March          3 2     2068.
    ##  6 2015  February       2 2     2104.
    ##  7 2015  January        1 2     1995.
    ##  8 2014  December      12 1     2059.
    ##  9 2014  November      11 3     2068.
    ## 10 2014  October       10 1     2018.
    ## # … with 777 more rows

Read in Problem 3 This problem uses the FiveThirtyEight data; these data
were gathered to create the interactive graphic on this page. In
particular, we’ll use the data in pols-month.csv, unemployment.csv, and
snp.csv. Our goal is to merge these into a single data frame using year
and month as keys across datasets.

First, clean the data in pols-month.csv. Use separate() to break up the
variable mon into integer variables year, month, and day; replace month
number with month name; create a president variable taking values gop
and dem, and remove prez\_dem and prez\_gop; and remove the day
variable.

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

Join the datasets by merging snp into pols, and merging unemployment
into the result.

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

Note: we could have used a date variable as a key instead of creating
year and month keys; doing so would help with some kinds of plotting,
and be a more accurate representation of the data. Date formats are
tricky, though. For more information check out the lubridate package in
the tidyverse.

Optional post-assignment survey If you’d like, a you can complete this
short survey after you’ve finished the assignment.
